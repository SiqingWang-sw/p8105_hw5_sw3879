p8105_hw5_sw3879
================
Siqing Wang
2023-11-11

## Problem 1

Read in the raw data, create a new `city_state` variable

``` r
homicide = read.csv("data/homicide-data.csv") |> 
  janitor::clean_names() |> 
  mutate(
    city_state = paste(city, state, sep = ", ")
  )
```

The raw dataset has 52179 observations and 13 variables, which are uid,
reported_date, victim_last, victim_first, victim_race, victim_age,
victim_sex, city, state, lat, lon, disposition, city_state

Summarize within cities

``` r
homicide_summary = homicide |> group_by(city_state) |> 
   summarize(total_homicides = n(),
             unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))
   )

homicide_summary
```

    ## # A tibble: 51 × 3
    ##    city_state      total_homicides unsolved_homicides
    ##    <chr>                     <int>              <int>
    ##  1 Albuquerque, NM             378                146
    ##  2 Atlanta, GA                 973                373
    ##  3 Baltimore, MD              2827               1825
    ##  4 Baton Rouge, LA             424                196
    ##  5 Birmingham, AL              800                347
    ##  6 Boston, MA                  614                310
    ##  7 Buffalo, NY                 521                319
    ##  8 Charlotte, NC               687                206
    ##  9 Chicago, IL                5535               4073
    ## 10 Cincinnati, OH              694                309
    ## # ℹ 41 more rows

Estimate the proportion of homicides that are unsolved in Baltimore MD

``` r
baltimore_test = prop.test(
  homicide_summary |> filter(city_state == "Baltimore, MD") |> pull(unsolved_homicides),
  homicide_summary |> filter(city_state == "Baltimore, MD") |> pull(total_homicides)
) |>  broom::tidy()
```

The estimated proportion of unsolved homicides is 0.6455607. The
confidence interval is \[0.6275625, 0.6631599\].

Run prop test for each city

``` r
nested_summary = homicide_summary %>%
  nest(total_homicides, unsolved_homicides)
```

    ## Warning: Supplying `...` without names was deprecated in tidyr 1.0.0.
    ## ℹ Please specify a name for each selection.
    ## ℹ Did you want `data = c(total_homicides, unsolved_homicides)`?
    ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was
    ## generated.

``` r
all_cities_test = nested_summary %>%
  mutate(test_result = map(data, ~ prop.test(.x$unsolved_homicides, .x$total_homicides)))
```

    ## Warning: There was 1 warning in `mutate()`.
    ## ℹ In argument: `test_result = map(data, ~prop.test(.x$unsolved_homicides,
    ##   .x$total_homicides))`.
    ## Caused by warning in `prop.test()`:
    ## ! Chi-squared approximation may be incorrect

``` r
all_cities_tidy = all_cities_test |> mutate(
    estimate = map_dbl(test_result, ~.x$estimate),
    conf_interval = map(test_result, glance),
    conf_interval_low = map_dbl(conf_interval, "conf.low"),
    conf_interval_high = map_dbl(conf_interval, "conf.high")
  ) %>%
  select(city_state, estimate, conf_interval_low, conf_interval_high) |> 
  filter(!estimate == 0)
```

Create a plot

``` r
all_cities_tidy |> 
  mutate(city_state = fct_reorder(city_state,estimate))|>
  ggplot(aes(x = city_state, y = estimate)) + 
  geom_errorbar(aes(ymin = conf_interval_low, ymax = conf_interval_high)) +
  geom_point() +
  theme(axis.text.x=element_text(angle = 45,hjust = 1)) +
  labs(title = "Estimates and Confidence Intervals for Unsolved Homicides by City",
       x = "City, State",
       y = "Estimated Proportion of Unsolved Homicides") +
  theme(axis.text.x = element_text(size = 7))
```

![](p8105_hw5_sw3879_files/figure-gfm/unnamed-chunk-6-1.png)<!-- -->

## Problem 2

Get file names and read in data

``` r
file_names = list.files("hw5_data", full.names = TRUE)
q2_raw = map(file_names, read.csv)
q2_combined = map2(file_names, q2_raw, ~mutate(.y, file_name = .x)) |> 
  bind_rows()
```

Creating a tidy dataframe

``` r
q2_tidy = q2_combined |> 
  separate(file_name, into = c("path", "file"), sep = "/") |> 
  separate(file, into = c("arm", "id"), sep = "_|\\.") |> 
  select(-path) |> 
    pivot_longer(
    cols = starts_with("week_"),
    names_to = "week", 
    values_to = "value"  
  ) |> 
  mutate(week = substr(week, 6, 7)) |> 
  mutate(week = as.numeric(week)) |> 
  mutate(
    arm = case_match(
      arm,
      "con" ~ "Control",
      "exp" ~ "Experimental"
    )
  )
```

    ## Warning: Expected 2 pieces. Additional pieces discarded in 20 rows [1, 2, 3, 4, 5, 6, 7,
    ## 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20].

Making the spaghetti plot

``` r
q2_tidy |> ggplot(aes(x = week, y = value, color = arm)) +
  geom_line() +
  facet_wrap(~id) +
  labs(title = "Control vs. Experiment data for each arm",
       x = "Week",
       y = "Data Value")
```

![](p8105_hw5_sw3879_files/figure-gfm/unnamed-chunk-9-1.png)<!-- -->
Based on the plot, we can see that for most of the 10 participants, the
experimental group has higher data value observations compared with
control group. The general trend of the experimental group is data is
increasing across weeks, while there is no clear trend for the control
data.

## Problem 3

Set up experiment

``` r
set.seed(1)
n = 30
sigma = 5
mu_values = 0:6
reps = 5000
power_results = data.frame()
estimate_results = data.frame()
```

Set up function

``` r
test_func = function(data, true_mu = 0) {
  t_test_result = tidy(t.test(data, mu = true_mu))
  p_value = t_test_result$p.value
  estimate = t_test_result$estimate
  
  return(list(p_value = p_value, estimate = estimate))
}
```

Run the function

``` r
for (mu in mu_values) {
  rejected_count = 0
  rejected_estimates = c()
  estimates = c()
  
  for (i in 1:reps) {
    data = rnorm(n, mean = mu, sd = sigma)
    test_result = test_func(data)
    
    if (test_result$p_value < 0.05) {
      rejected_count = rejected_count + 1
      rejected_estimates = c(rejected_estimates, test_result$estimate)
    } 
    
    estimates = c(estimates, test_result$estimate)
    
  }
  
  power = rejected_count / reps
  
  power_results = rbind(power_results, data.frame(mu = mu, power = power))
  
  if (length(rejected_estimates) > 0) {
    avg_estimate_rejected = mean(rejected_estimates)
  } else {
    avg_estimate_rejected = NA
  }
  
  avg_estimate = mean(estimates)
  
  estimate_results = rbind(estimate_results, data.frame(mu = mu, avg_estimate = avg_estimate, avg_estimate_rejected = avg_estimate_rejected))
}
```

``` r
ggplot(power_results, aes(x = mu, y = power)) +
  geom_point() + geom_line() +
  labs(title = "proportion of null rejected vs. true μ",
    x = "True value of μ", y = "Power")
```

![](p8105_hw5_sw3879_files/figure-gfm/unnamed-chunk-13-1.png)<!-- -->

Effect size is the difference in means between the two groups divided by
the standard deviation of the null group. In this case, as we test
through different true μ against H0 = 0, as true μ increases, effect
size increases. And according to the plot, the power increases as effect
size increases, reach power = 1 when true μ = 6.

``` r
ggplot(estimate_results, aes(x = mu, y = avg_estimate)) +
  geom_line(aes(color = "avg estimate"), show.legend = TRUE) + geom_point() +
  labs(title = "μ_hat estimate vs. true μ",
       x = "True value of μ", 
       y = "Average μ̂") +
 geom_point(data = estimate_results, aes(y = avg_estimate_rejected, 
            color = "avg rejected estimate"), show.legend = TRUE) +
  scale_color_manual(values = c("avg estimate" = "blue", "avg rejected estimate" = "red"), labels = c("avg estimate", "avg rejected estimate")) 
```

![](p8105_hw5_sw3879_files/figure-gfm/unnamed-chunk-14-1.png)<!-- -->

When true μ = 0 or when true μ is larget (\> 4), we can see that the
average estimate of μ_hat when null is rejected is equal to the true μ.
When the true μ = 0, we are testing this against the H0 μ = 0, so both
estimates will be close. When true μ is 1 - 3, this deviation starts out
large and gradually becomes smaller, because more and more reps out of
the 5000 gets rejected, and the estimate from the rejected group will
tend toward the true μ. By when true μ is very large, basically all reps
out of the 5000 reps get rejected, so the estimate from the rejected
group would again be very similar to the true μ.
