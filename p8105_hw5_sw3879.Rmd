---
title: "p8105_hw5_sw3879"
author: "Siqing Wang"
date: "2023-11-11"
output: github_document
---

```{r, include = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(dplyr)
library(purrr)
library(tidyr)
library(broom)
library(ggplot2)
library(forcats)
```

## Problem 1

Read in the raw data, create a new `city_state` variable
```{r}
homicide = read.csv("data/homicide-data.csv") |> 
  janitor::clean_names() |> 
  mutate(
    city_state = paste(city, state, sep = ", ")
  )
```

The raw dataset has `r nrow(homicide)` observations and `r ncol(homicide)` variables, which are `r colnames(homicide)`

Summarize within cities
```{r}
homicide_summary = homicide |> group_by(city_state) |> 
   summarize(total_homicides = n(),
             unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))
   )

homicide_summary
```

Estimate the proportion of homicides that are unsolved in Baltimore MD
```{r}
baltimore_test = prop.test(
  homicide_summary |> filter(city_state == "Baltimore, MD") |> pull(unsolved_homicides),
  homicide_summary |> filter(city_state == "Baltimore, MD") |> pull(total_homicides)
) |>  broom::tidy()
```

The estimated proportion of unsolved homicides is `r baltimore_test |> pull(estimate)`. 
The confidence interval is [`r baltimore_test |> pull(conf.low)`, `r baltimore_test |> pull(conf.high)`].

Run prop test for each city
```{r}
nested_summary = homicide_summary %>%
  nest(total_homicides, unsolved_homicides)

all_cities_test = nested_summary %>%
  mutate(test_result = map(data, ~ prop.test(.x$unsolved_homicides, .x$total_homicides)))

all_cities_tidy = all_cities_test |> mutate(
    estimate = map_dbl(test_result, ~.x$estimate),
    conf_interval = map(test_result, glance),
    conf_interval_low = map_dbl(conf_interval, "conf.low"),
    conf_interval_high = map_dbl(conf_interval, "conf.high")
  ) %>%
  select(city_state, estimate, conf_interval_low, conf_interval_high) |> 
  filter(!estimate == 0)
```

Create a plot
```{r}
all_cities_tidy |> 
  mutate(city_state = fct_reorder(city_state,estimate))|>
  ggplot(aes(x = city_state, y = estimate)) + 
  geom_errorbar(aes(ymin = conf_interval_low, ymax = conf_interval_high)) +
  geom_point() +
  theme(axis.text.x=element_text(angle = 45,hjust = 1)) +
  labs(title = "Estimates and Confidence Intervals for Unsolved Homicides by City",
       x = "City, State",
       y = "Estimated Proportion of Unsolved Homicides") +
  theme(axis.text.x = element_text(size = 7))
```

## Problem 2

Get file names and read in data
```{r}
file_names = list.files("hw5_data", full.names = TRUE)
q2_raw = map(file_names, read.csv)
q2_combined = map2(file_names, q2_raw, ~mutate(.y, file_name = .x)) |> 
  bind_rows()
```

Creating a tidy dataframe 
```{r}
q2_tidy = q2_combined |> 
  separate(file_name, into = c("path", "file"), sep = "/") |> 
  separate(file, into = c("arm", "id"), sep = "_|\\.") |> 
  select(-path) |> 
    pivot_longer(
    cols = starts_with("week_"),
    names_to = "week", 
    values_to = "value"  
  ) |> 
  mutate(week = substr(week, 6, 7)) |> 
  mutate(week = as.numeric(week)) |> 
  mutate(
    arm = case_match(
      arm,
      "con" ~ "Control",
      "exp" ~ "Experimental"
    )
  )
```

Making the spaghetti plot
```{r}
q2_tidy |> ggplot(aes(x = week, y = value, color = arm)) +
  geom_line() +
  facet_wrap(~id) +
  labs(title = "Control vs. Experiment data for each arm",
       x = "Week",
       y = "Data Value")
```
Based on the plot, we can see that for most of the 10 participants, the experimental group has higher data value observations compared with control group. The general trend of the experimental group is data is increasing across weeks, while there is no clear trend for the control data. 

## Problem 3

Set up experiment
```{r}
set.seed(1)
n = 30
sigma = 5
mu_values = 0:6
reps = 5000
power_results = data.frame()
estimate_results = data.frame()
```

Set up function
```{r}
test_func = function(data, true_mu = 0) {
  t_test_result = tidy(t.test(data, mu = true_mu))
  p_value = t_test_result$p.value
  estimate = t_test_result$estimate
  
  return(list(p_value = p_value, estimate = estimate))
}
```

Run the function
```{r}
for (mu in mu_values) {
  rejected_count = 0
  rejected_estimates = c()
  estimates = c()
  
  for (i in 1:reps) {
    data = rnorm(n, mean = mu, sd = sigma)
    test_result = test_func(data)
    
    if (test_result$p_value < 0.05) {
      rejected_count = rejected_count + 1
      rejected_estimates = c(rejected_estimates, test_result$estimate)
    } 
    
    estimates = c(estimates, test_result$estimate)
    
  }
  
  power = rejected_count / reps
  
  power_results = rbind(power_results, data.frame(mu = mu, power = power))
  
  if (length(rejected_estimates) > 0) {
    avg_estimate_rejected = mean(rejected_estimates)
  } else {
    avg_estimate_rejected = NA
  }
  
  avg_estimate = mean(estimates)
  
  estimate_results = rbind(estimate_results, data.frame(mu = mu, avg_estimate = avg_estimate, avg_estimate_rejected = avg_estimate_rejected))
}
```

```{r}
ggplot(power_results, aes(x = mu, y = power)) +
  geom_point() + geom_line() +
  labs(title = "proportion of null rejected vs. true μ",
    x = "True value of μ", y = "Power")
```

Effect size is the difference in means between the two groups divided by the standard deviation of the null group. In this case, as we test through different true μ against H0 = 0, as true μ increases, effect size increases. And according to the plot, the power increases as effect size increases, reach power = 1 when true μ = 6. 

```{r}
ggplot(estimate_results, aes(x = mu, y = avg_estimate)) +
  geom_line(aes(color = "avg estimate"), show.legend = TRUE) + geom_point() +
  labs(title = "μ_hat estimate vs. true μ",
       x = "True value of μ", 
       y = "Average μ̂") +
 geom_point(data = estimate_results, aes(y = avg_estimate_rejected, 
            color = "avg rejected estimate"), show.legend = TRUE) +
  scale_color_manual(values = c("avg estimate" = "blue", "avg rejected estimate" = "red"), labels = c("avg estimate", "avg rejected estimate")) 
```

When true μ = 0 or when true μ is larget (> 4), we can see that the average estimate of μ_hat when null is rejected is equal to the true μ. When the true μ = 0, we are testing this against the H0 μ = 0, so both estimates will be close. When true μ is 1 - 3, this deviation starts out large and gradually becomes smaller, because more and more reps out of the 5000 gets rejected, and the estimate from the rejected group will tend toward the true μ. By when true μ is very large, basically all reps out of the 5000 reps get rejected, so the estimate from the rejected group would again be very similar to the true μ. 


